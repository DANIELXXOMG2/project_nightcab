"""
Script 03: Procesamiento y FusiÃ³n de Datos
===========================================
Pipeline completo de preprocesamiento que:
1. Carga datos de Divvy desde mÃºltiples archivos CSV
2. Carga datos meteorolÃ³gicos procesados
3. Limpia y transforma ambos DataFrames
4. Fusiona los datos por timestamp horario
5. Guarda el dataset maestro en formato Parquet
"""

import os
import glob
import pandas as pd
import numpy as np
from pathlib import Path


def load_divvy_data(raw_data_path: str = "./data/raw/") -> pd.DataFrame:
    """
    Carga todos los archivos CSV de Divvy en un Ãºnico DataFrame.
    
    Args:
        raw_data_path: Ruta a la carpeta con archivos CSV de Divvy
        
    Returns:
        DataFrame consolidado con todos los datos de Divvy
    """
    print("=" * 60)
    print("ğŸ“‚ PASO 1: CARGA DE DATOS DE DIVVY")
    print("=" * 60)
    
    # Buscar todos los archivos CSV en la carpeta raw
    csv_pattern = os.path.join(raw_data_path, "*-divvy-tripdata.csv")
    csv_files = glob.glob(csv_pattern)
    
    if not csv_files:
        raise FileNotFoundError(f"No se encontraron archivos CSV en {raw_data_path}")
    
    print(f"âœ… Encontrados {len(csv_files)} archivos CSV:")
    for file in csv_files:
        print(f"   - {os.path.basename(file)}")
    
    # Cargar y concatenar todos los archivos
    dataframes = []
    for file in csv_files:
        df = pd.read_csv(file)
        dataframes.append(df)
        print(f"   âœ“ Cargado: {os.path.basename(file)} ({len(df):,} filas)")
    
    # Concatenar todos los DataFrames
    divvy_df = pd.concat(dataframes, ignore_index=True)
    
    print(f"\nğŸ“Š Total de filas cargadas: {len(divvy_df):,}")
    print(f"ğŸ“Š Total de columnas: {len(divvy_df.columns)}")
    print(f"ğŸ“Š Memoria utilizada: {divvy_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    return divvy_df


def load_weather_data(weather_path: str = "./data/processed/weather_data.csv") -> pd.DataFrame:
    """
    Carga los datos meteorolÃ³gicos procesados.
    
    Args:
        weather_path: Ruta al archivo CSV del clima
        
    Returns:
        DataFrame con datos meteorolÃ³gicos
    """
    print("\n" + "=" * 60)
    print("ğŸŒ¤ï¸  PASO 2: CARGA DE DATOS METEOROLÃ“GICOS")
    print("=" * 60)
    
    if not os.path.exists(weather_path):
        raise FileNotFoundError(f"No se encontrÃ³ el archivo: {weather_path}")
    
    weather_df = pd.read_csv(weather_path)
    
    print(f"âœ… Archivo cargado: {os.path.basename(weather_path)}")
    print(f"ğŸ“Š Total de filas: {len(weather_df):,}")
    print(f"ğŸ“Š Total de columnas: {len(weather_df.columns)}")
    print(f"ğŸ“Š Columnas disponibles: {', '.join(weather_df.columns.tolist())}")
    
    return weather_df


def clean_divvy_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Limpia y procesa el DataFrame de Divvy.
    
    Args:
        df: DataFrame de Divvy sin procesar
        
    Returns:
        DataFrame limpio y procesado
    """
    print("\n" + "=" * 60)
    print("ğŸ§¹ PASO 3: LIMPIEZA Y PROCESAMIENTO DE DATOS DIVVY")
    print("=" * 60)
    
    initial_rows = len(df)
    print(f"ğŸ“Š Filas iniciales: {initial_rows:,}")
    
    # 1. Convertir columnas de fecha a datetime
    print("\nğŸ”„ Convirtiendo columnas de fecha a datetime...")
    df['started_at'] = pd.to_datetime(df['started_at'], errors='coerce')
    df['ended_at'] = pd.to_datetime(df['ended_at'], errors='coerce')
    print("   âœ“ Columnas 'started_at' y 'ended_at' convertidas a datetime")
    
    # 2. Calcular duraciÃ³n del viaje en minutos
    print("\nâ±ï¸  Calculando duraciÃ³n de viajes...")
    df['trip_duration_minutes'] = (df['ended_at'] - df['started_at']).dt.total_seconds() / 60
    print("   âœ“ Columna 'trip_duration_minutes' creada")
    
    # 3. Eliminar viajes invÃ¡lidos (duraciÃ³n negativa o cero)
    invalid_duration = df['trip_duration_minutes'] <= 0
    print(f"\nâŒ Eliminando {invalid_duration.sum():,} viajes con duraciÃ³n invÃ¡lida (â‰¤0 minutos)")
    df = df[~invalid_duration].copy()
    
    # 4. Eliminar filas con valores nulos en columnas clave
    print("\nğŸ” Eliminando filas con valores nulos en columnas clave...")
    key_columns = ['start_station_name', 'end_station_name', 'started_at', 'ended_at']
    
    nulls_before = df[key_columns].isnull().sum()
    print("   Valores nulos por columna:")
    for col in key_columns:
        print(f"     - {col}: {nulls_before[col]:,}")
    
    df = df.dropna(subset=key_columns).copy()
    rows_removed = initial_rows - len(df)
    print(f"\n   âœ“ Total de filas eliminadas: {rows_removed:,}")
    print(f"   âœ“ Filas restantes: {len(df):,}")
    
    # 5. Crear columna datetime_hourly (redondear a la hora)
    print("\nğŸ• Creando columna 'datetime_hourly' (redondeada a la hora)...")
    df['datetime_hourly'] = df['started_at'].dt.floor('H')
    print("   âœ“ Columna 'datetime_hourly' creada")
    print(f"   ğŸ“… Ejemplo: {df['started_at'].iloc[0]} â†’ {df['datetime_hourly'].iloc[0]}")
    
    # Resumen de estadÃ­sticas de duraciÃ³n
    print("\nğŸ“ˆ EstadÃ­sticas de duraciÃ³n de viajes:")
    print(f"   - DuraciÃ³n mÃ­nima: {df['trip_duration_minutes'].min():.2f} minutos")
    print(f"   - DuraciÃ³n mÃ¡xima: {df['trip_duration_minutes'].max():.2f} minutos")
    print(f"   - DuraciÃ³n promedio: {df['trip_duration_minutes'].mean():.2f} minutos")
    print(f"   - DuraciÃ³n mediana: {df['trip_duration_minutes'].median():.2f} minutos")
    
    return df


def clean_weather_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Limpia y procesa el DataFrame meteorolÃ³gico.
    
    Args:
        df: DataFrame meteorolÃ³gico sin procesar
        
    Returns:
        DataFrame limpio y procesado
    """
    print("\n" + "=" * 60)
    print("ğŸ§¹ PASO 4: LIMPIEZA Y PROCESAMIENTO DE DATOS METEOROLÃ“GICOS")
    print("=" * 60)
    
    # Convertir columna datetime a formato datetime
    print("\nğŸ”„ Convirtiendo columna 'datetime' a formato datetime...")
    df['datetime'] = pd.to_datetime(df['datetime'], errors='coerce')
    print("   âœ“ Columna 'datetime' convertida correctamente")
    
    # Verificar valores nulos
    null_count = df['datetime'].isnull().sum()
    if null_count > 0:
        print(f"   âš ï¸  Encontrados {null_count} valores nulos en 'datetime'")
        df = df.dropna(subset=['datetime']).copy()
        print(f"   âœ“ Filas eliminadas: {null_count}")
    else:
        print("   âœ“ No se encontraron valores nulos en 'datetime'")
    
    print(f"\nğŸ“Š Filas finales: {len(df):,}")
    print(f"ğŸ“… Rango de fechas: {df['datetime'].min()} a {df['datetime'].max()}")
    
    return df


def merge_datasets(divvy_df: pd.DataFrame, weather_df: pd.DataFrame) -> pd.DataFrame:
    """
    Fusiona los DataFrames de Divvy y clima por timestamp horario.
    
    Args:
        divvy_df: DataFrame de Divvy procesado
        weather_df: DataFrame meteorolÃ³gico procesado
        
    Returns:
        DataFrame fusionado
    """
    print("\n" + "=" * 60)
    print("ğŸ”— PASO 5: FUSIÃ“N DE DATASETS")
    print("=" * 60)
    
    print(f"\nğŸ“Š Filas antes de fusiÃ³n:")
    print(f"   - Divvy: {len(divvy_df):,}")
    print(f"   - Clima: {len(weather_df):,}")
    
    # Realizar fusiÃ³n LEFT JOIN
    print("\nğŸ”„ Realizando fusiÃ³n (LEFT JOIN) en datetime_hourly = datetime...")
    merged_df = pd.merge(
        divvy_df,
        weather_df,
        left_on='datetime_hourly',
        right_on='datetime',
        how='left',
        suffixes=('', '_weather')
    )
    
    print(f"   âœ“ FusiÃ³n completada: {len(merged_df):,} filas")
    
    # Verificar registros sin datos meteorolÃ³gicos
    missing_weather = merged_df['datetime'].isnull().sum()
    if missing_weather > 0:
        print(f"\n   âš ï¸  {missing_weather:,} registros sin datos meteorolÃ³gicos coincidentes")
        print(f"   ğŸ“Š Porcentaje sin clima: {(missing_weather / len(merged_df) * 100):.2f}%")
    else:
        print("\n   âœ… Todos los registros tienen datos meteorolÃ³gicos")
    
    # Eliminar columna datetime duplicada del clima
    if 'datetime' in merged_df.columns:
        merged_df = merged_df.drop('datetime', axis=1)
        print("   âœ“ Columna 'datetime' duplicada eliminada")
    
    print(f"\nğŸ“Š Columnas totales en dataset fusionado: {len(merged_df.columns)}")
    print(f"ğŸ“Š Memoria utilizada: {merged_df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
    
    return merged_df


def save_parquet(df: pd.DataFrame, output_path: str = "./data/processed/master_dataset.parquet") -> None:
    """
    Guarda el DataFrame en formato Parquet.
    
    Args:
        df: DataFrame a guardar
        output_path: Ruta del archivo de salida
    """
    print("\n" + "=" * 60)
    print("ğŸ’¾ PASO 6: GUARDADO DEL DATASET MAESTRO")
    print("=" * 60)
    
    # Crear directorio si no existe
    output_dir = os.path.dirname(output_path)
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    
    print(f"\nğŸ“ Guardando en: {output_path}")
    
    # Guardar en formato Parquet
    df.to_parquet(output_path, index=False, engine='pyarrow', compression='snappy')
    
    # Obtener tamaÃ±o del archivo
    file_size = os.path.getsize(output_path) / 1024**2
    
    print(f"   âœ… Archivo guardado exitosamente")
    print(f"   ğŸ“Š TamaÃ±o del archivo: {file_size:.2f} MB")
    print(f"   ğŸ“Š Filas guardadas: {len(df):,}")
    print(f"   ğŸ“Š Columnas guardadas: {len(df.columns)}")
    
    # Mostrar columnas guardadas
    print("\nğŸ“‹ Columnas en el dataset maestro:")
    for i, col in enumerate(df.columns, 1):
        print(f"   {i:2d}. {col}")


def main():
    """
    FunciÃ³n principal que ejecuta el pipeline completo.
    """
    print("\n" + "=" * 60)
    print("ğŸš€ INICIANDO PIPELINE DE PROCESAMIENTO Y FUSIÃ“N DE DATOS")
    print("=" * 60)
    
    try:
        # 1. Cargar datos de Divvy
        divvy_df = load_divvy_data()
        
        # 2. Cargar datos meteorolÃ³gicos
        weather_df = load_weather_data()
        
        # 3. Limpiar datos de Divvy
        divvy_df = clean_divvy_data(divvy_df)
        
        # 4. Limpiar datos meteorolÃ³gicos
        weather_df = clean_weather_data(weather_df)
        
        # 5. Fusionar datasets
        master_df = merge_datasets(divvy_df, weather_df)
        
        # 6. Guardar dataset maestro
        save_parquet(master_df)
        
        print("\n" + "=" * 60)
        print("âœ… PIPELINE COMPLETADO EXITOSAMENTE")
        print("=" * 60)
        print(f"\nğŸ‰ Dataset maestro listo en: ./data/processed/master_dataset.parquet")
        print(f"ğŸ“Š Total de registros: {len(master_df):,}")
        print(f"ğŸ“Š Total de columnas: {len(master_df.columns)}")
        
    except Exception as e:
        print("\n" + "=" * 60)
        print("âŒ ERROR EN EL PIPELINE")
        print("=" * 60)
        print(f"\nğŸš¨ {type(e).__name__}: {str(e)}")
        raise


if __name__ == "__main__":
    main()
